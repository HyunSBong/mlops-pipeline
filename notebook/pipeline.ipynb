{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "from src import clean_text, get_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     ./nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to ./nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to ./nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to ./nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to ./nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger', download_dir='./nltk_data')\n",
    "nltk.download('punkt', download_dir='./nltk_data')\n",
    "nltk.download('punkt_tab', download_dir='./nltk_data')\n",
    "nltk.download('stopwords', download_dir='./nltk_data')\n",
    "nltk.download('wordnet', download_dir='./nltk_data')\n",
    "nltk.data.path.append('./nltk_data')\n",
    "nltk.data.path.append('/home/hyunsu/project/ku_stat/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunsu/anaconda3/envs/dnabert/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/hyunsu/anaconda3/envs/dnabert/lib/python3.8/site-packages/transformers/modeling_utils.py:446: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "## DistilBERT\n",
    "model_checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "distil_bert_model = pipeline(task=\"sentiment-analysis\", model=model_checkpoint)\n",
    "\n",
    "## FinBERT\n",
    "model_checkpoint = \"yiyanghkust/finbert-tone\"\n",
    "finbert = BertForSequenceClassification.from_pretrained(model_checkpoint,num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
    "finbert_model = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_utc(utc_time):\n",
    "    return datetime.utcfromtimestamp(utc_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_posts_subreddit_pipeline(reddit_data, sentiment_model):\n",
    "    df = pd.DataFrame(reddit_data)\n",
    "    df['all_text'] = df['title'] + df['selftext']\n",
    "    df['clean_title'] = df['all_text'].apply(lambda x : clean_text(x))\n",
    "    df = get_sentiment(df, 'clean_title', sentiment_model)\n",
    "    df['timestamp'] = df['created_utc'].apply(convert_utc)\n",
    "\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_pipeline(df, comment_column, column_to_clean, sentiment_model):\n",
    "    # Get comment data from the pipeline_subreddit\n",
    "    if comment_column in df.columns:\n",
    "        comments_df = pd.DataFrame(df[comment_column][df.index[0]])\n",
    "        if column_to_clean in comments_df.columns:\n",
    "            comments_df[f'clean_{column_to_clean}'] = comments_df[column_to_clean].apply(lambda x : clean_text(x))\n",
    "            comments_df = get_sentiment(comments_df, f'clean_{column_to_clean}', sentiment_model) \n",
    "            comments_df['timestamp'] = comments_df['created_utc'].apply(convert_utc)\n",
    "            return comments_df\n",
    "        else:\n",
    "            return comments_df\n",
    "    else: return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(df, post_id):\n",
    "    return df[df['title'] == post_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './reddit_data/reddit_data_stoks_hot_10.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    reddit_data_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data_sample_transformed = top_posts_subreddit_pipeline(reddit_data_sample, sentiment_model = finbert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data_sample_comment_transformed = comments_pipeline(reddit_data_sample_transformed, 'comments', 'body', sentiment_model = finbert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_top_level</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>depth</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>sentiment_clean_body_label</th>\n",
       "      <th>sentiment_clean_body_score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Late 20s. Decided to keep it simple on splitti...</td>\n",
       "      <td>Hariharan235</td>\n",
       "      <td>13</td>\n",
       "      <td>1.744035e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_1j0w73o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>late decide keep simple splitting position adj...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>2025-04-07 14:13:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100% S&amp;P and bricking it</td>\n",
       "      <td>Jimlad73</td>\n",
       "      <td>14</td>\n",
       "      <td>1.741096e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_1j0w73o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sp bricke</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.992054</td>\n",
       "      <td>2025-03-04 13:54:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100% 6-month tbills, lol :)</td>\n",
       "      <td>inopia</td>\n",
       "      <td>11</td>\n",
       "      <td>1.741652e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_1j0w73o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>month tbill lol</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>2025-03-11 00:18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticker &amp; %\\n\\nSPGI: 18.2%\\n\\nASML: 15.2%\\n\\nGO...</td>\n",
       "      <td>elgrandorado</td>\n",
       "      <td>7</td>\n",
       "      <td>1.741881e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_1j0w73o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ticker spgi asml goog mco hwkn ntdoy v manh</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>2025-03-13 15:57:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VOO 19.5%\\n\\nTSLA 19%\\n\\nGOOG 14.5%\\n\\nBRK.B 4...</td>\n",
       "      <td>FromTheBottomO_o</td>\n",
       "      <td>7</td>\n",
       "      <td>1.745790e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_1j0w73o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>voo tsla goog brkb amzn aapl nvda</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>2025-04-27 21:36:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>I’m sorry but being able to understand a balan...</td>\n",
       "      <td>Short-Philosophy-105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.741077e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_mfxgp3k</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry able understand balance sheet analyse co...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>2025-03-04 08:22:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.741077e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_mfxgwyz</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>delete</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.986192</td>\n",
       "      <td>2025-03-04 08:24:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.741077e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_mfxh6pr</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>delete</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.986192</td>\n",
       "      <td>2025-03-04 08:27:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.741077e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_mfxhfgm</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>delete</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.986192</td>\n",
       "      <td>2025-03-04 08:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.741077e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_mfxhkf6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>delete</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.986192</td>\n",
       "      <td>2025-03-04 08:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body                author  \\\n",
       "0    Late 20s. Decided to keep it simple on splitti...          Hariharan235   \n",
       "1                             100% S&P and bricking it              Jimlad73   \n",
       "2                          100% 6-month tbills, lol :)                inopia   \n",
       "3    Ticker & %\\n\\nSPGI: 18.2%\\n\\nASML: 15.2%\\n\\nGO...          elgrandorado   \n",
       "4    VOO 19.5%\\n\\nTSLA 19%\\n\\nGOOG 14.5%\\n\\nBRK.B 4...      FromTheBottomO_o   \n",
       "..                                                 ...                   ...   \n",
       "282  I’m sorry but being able to understand a balan...  Short-Philosophy-105   \n",
       "283                                          [deleted]                  None   \n",
       "284                                          [deleted]                  None   \n",
       "285                                          [deleted]                  None   \n",
       "286                                          [deleted]                  None   \n",
       "\n",
       "     score   created_utc  is_top_level   parent_id  depth  gilded  \\\n",
       "0       13  1.744035e+09          True  t3_1j0w73o      0       0   \n",
       "1       14  1.741096e+09          True  t3_1j0w73o      0       0   \n",
       "2       11  1.741652e+09          True  t3_1j0w73o      0       0   \n",
       "3        7  1.741881e+09          True  t3_1j0w73o      0       0   \n",
       "4        7  1.745790e+09          True  t3_1j0w73o      0       0   \n",
       "..     ...           ...           ...         ...    ...     ...   \n",
       "282      1  1.741077e+09         False  t1_mfxgp3k      4       0   \n",
       "283      1  1.741077e+09         False  t1_mfxgwyz      5       0   \n",
       "284      1  1.741077e+09         False  t1_mfxh6pr      6       0   \n",
       "285      1  1.741077e+09         False  t1_mfxhfgm      7       0   \n",
       "286      1  1.741077e+09         False  t1_mfxhkf6      8       0   \n",
       "\n",
       "                                            clean_body  \\\n",
       "0    late decide keep simple splitting position adj...   \n",
       "1                                            sp bricke   \n",
       "2                                      month tbill lol   \n",
       "3          ticker spgi asml goog mco hwkn ntdoy v manh   \n",
       "4                    voo tsla goog brkb amzn aapl nvda   \n",
       "..                                                 ...   \n",
       "282  sorry able understand balance sheet analyse co...   \n",
       "283                                             delete   \n",
       "284                                             delete   \n",
       "285                                             delete   \n",
       "286                                             delete   \n",
       "\n",
       "    sentiment_clean_body_label  sentiment_clean_body_score           timestamp  \n",
       "0                      Neutral                    0.999952 2025-04-07 14:13:26  \n",
       "1                      Neutral                    0.992054 2025-03-04 13:54:48  \n",
       "2                      Neutral                    0.999989 2025-03-11 00:18:18  \n",
       "3                      Neutral                    0.999991 2025-03-13 15:57:56  \n",
       "4                      Neutral                    0.999992 2025-04-27 21:36:49  \n",
       "..                         ...                         ...                 ...  \n",
       "282                    Neutral                    0.999349 2025-03-04 08:22:04  \n",
       "283                    Neutral                    0.986192 2025-03-04 08:24:55  \n",
       "284                    Neutral                    0.986192 2025-03-04 08:27:32  \n",
       "285                    Neutral                    0.986192 2025-03-04 08:29:00  \n",
       "286                    Neutral                    0.986192 2025-03-04 08:30:00  \n",
       "\n",
       "[287 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data_sample_comment_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ku_stat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
